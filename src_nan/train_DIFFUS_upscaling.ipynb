{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "\n",
    "from DatasetCH import UpscaleDataset\n",
    "#from models import *\n",
    "import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dirs\n",
    "mdir=\"./Model_dif/Test_1\"\n",
    "rdir=\"./Results_dif/Test_1\"\n",
    "os.makedirs(mdir, exist_ok=True)\n",
    "os.makedirs(rdir, exist_ok=True)\n",
    "\n",
    "# Define the tensorboard writer\n",
    "writer = SummaryWriter(\"./Runs_dif/Test_1\") # was runs_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/mpyrina/Notebooks/ANEMOI/ClimateDiffuse/src/')\n",
    "from DatasetCH import *\n",
    "from TrainDiffusion import *\n",
    "#from TrainUnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN DIFFUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - new upscale with nan\n",
      "Loaded coarse data shape: (460, 11, 16, 32)\n",
      "Loaded high-resolution data shape: (460, 128, 256)\n",
      "Final coarse shape: torch.Size([5060, 1, 16, 32])\n",
      "Final fine shape: torch.Size([5060, 1, 128, 256])\n",
      "Input shape (should be [N, 1, H, W]): torch.Size([5060, 1, 128, 256])\n",
      "Dataset ready.\n",
      "Test - new upscale with nan\n",
      "Loaded coarse data shape: (138, 11, 16, 32)\n",
      "Loaded high-resolution data shape: (138, 128, 256)\n",
      "Final coarse shape: torch.Size([1518, 1, 16, 32])\n",
      "Final fine shape: torch.Size([1518, 1, 128, 256])\n",
      "Input shape (should be [N, 1, H, W]): torch.Size([1518, 1, 128, 256])\n",
      "Dataset ready.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 10\n",
    "accum = 4\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# a tensor of shape [B, C, H, W] mean that c=8, image resol=(H, W) \n",
    "\n",
    "network = Network.EDMPrecond(\n",
    "        img_resolution=(256, 128),\n",
    "        in_channels=2,\n",
    "        out_channels=1,\n",
    "        label_dim=0\n",
    "    ).to(device)\n",
    "\n",
    "# define the datasets\n",
    "ifs_dir = '/s2s/mpyrina/ECMWF_MCH/Europe_eval/s2s_hind_2022/all/'\n",
    "obs_dir = '/net/cfc/s2s_nobackup/mpyrina/TABSD_ifs_like/'\n",
    "\n",
    "dataset_train = UpscaleDataset(coarse_data_dir = ifs_dir, highres_data_dir = obs_dir,\n",
    "year_start=2002, year_end=2012, month=815,  \n",
    "constant_variables=None, constant_variables_filename=None)\n",
    "\n",
    "dataset_test = UpscaleDataset(coarse_data_dir = ifs_dir, highres_data_dir = obs_dir,\n",
    "year_start=2012, year_end=2015, month=815,  \n",
    "constant_variables=None, constant_variables_filename=None)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "optimiser = torch.optim.AdamW(network.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = EDMLoss()\n",
    "losses = []\n",
    "\n",
    "\n",
    "for step in range(num_epochs):\n",
    "    # model_save\n",
    "    model_save_path = f\"{mdir}/dif_model_epoch_{step}.pt\"\n",
    "    # fig_save\n",
    "    fig_save_path = f\"{rdir}/{step}.png\"\n",
    "    # best modes\n",
    "    mbest = f\"{mdir}/best_dif_model_epoch_{step}.pt\"\n",
    "\n",
    "    epoch_loss = training_step(network, loss_fn, optimiser,\n",
    "                                   dataloader_train, scaler, step,\n",
    "                                   accum, writer, device=device)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    torch.save(network.state_dict(), model_save_path)\n",
    "    \n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "    if losses[-1] == min(losses):\n",
    "        torch.save(network.state_dict(), mbest)\n",
    "        \n",
    "    if step % 5 == 0:\n",
    "        (fig, ax), (base_error, pred_error), predicted_numpy_array = sample_model_dif(network, dataloader_test, device=device)\n",
    "        plt.show()\n",
    "        fig.savefig(fig_save_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        writer.add_scalar(\"Error/base\", base_error, step)\n",
    "        writer.add_scalar(\"Error/pred\", pred_error, step)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig, ax), (base_error, pred_error), predicted_numpy_array = sample_model_dif(network, dataloader_test, device=device)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model saved to ./Model_dif/dif_model_epoch_0.pt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = f\"./Model_dif/dif_model_epoch_{step}.pt\"\n",
    "torch.save(network.state_dict(), model_save_path)\n",
    "(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### unet only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the datasets\n",
    "ifs_dir = '/s2s/mpyrina/ECMWF_MCH/Europe_eval/s2s_hind_2022/all/'\n",
    "obs_dir = '/net/cfc/s2s_nobackup/mpyrina/TABSD_ifs_like/'\n",
    "\n",
    "# Run training for small number of epochs \n",
    "num_epochs = 1\n",
    "## Select hyperparameters of training\n",
    "batch_size = 8\n",
    "learning_rate = 1e-5\n",
    "accum = 8\n",
    "\n",
    "dataset_train = UpscaleDataset(coarse_data_dir = ifs_dir, highres_data_dir = obs_dir,\n",
    "year_start=2005, year_end=2008, month=815,  \n",
    "constant_variables=None, constant_variables_filename=None)\n",
    "\n",
    "dataset_test = UpscaleDataset(coarse_data_dir = ifs_dir, highres_data_dir = obs_dir,\n",
    "year_start=2009, year_end=2010, month=815,  \n",
    "constant_variables=None, constant_variables_filename=None)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Define device\n",
    "device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# define the ml model : 1, 1, : 1 input var, one output\n",
    "unet_model = UNet((256, 128), 1, 1, label_dim=0, use_diffuse=True)\n",
    "unet_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# define the optimiser\n",
    "optimiser = torch.optim.AdamW(unet_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the tensorboard writer\n",
    "writer = SummaryWriter(\"./runs_unet\")\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# train the model\n",
    "losses = []\n",
    "for step in range(num_epochs):\n",
    "    epoch_loss = train_step(\n",
    "        unet_model, loss_fn, dataloader_train, optimiser,\n",
    "        scaler, step, accum, writer, device=device)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    # Save the model weights\n",
    "    model_save_path = f\"./Model/dif_model_epoch_{step}.pt\"\n",
    "    torch.save(unet_model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    (fig, ax), (base_error, pred_error), predicted_numpy_array = sample_model(\n",
    "        unet_model, dataloader_test, device=device)\n",
    "    plt.show()\n",
    "    fig.savefig(f\"./results_unet/{step}.png\", dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "    writer.add_scalar(\"Error/base\", base_error, step)\n",
    "    writer.add_scalar(\"Error/pred\", pred_error, step)\n",
    "\n",
    "    # save the model\n",
    "    if losses[-1] == min(losses):\n",
    "        torch.save(unet_model.state_dict(), f\"./Model/Models_dif/best_unet_model_epoch_{step}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv_iacpy3_2023]",
   "language": "python",
   "name": "conda-env-.conda-myenv_iacpy3_2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
