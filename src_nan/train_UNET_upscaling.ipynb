{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "\n",
    "from DatasetCH import UpscaleDataset\n",
    "#from models import *\n",
    "import Network\n",
    "\n",
    "# Make dirs\n",
    "mdir=\"./Model_unet/Test_1\"\n",
    "rdir=\"./Results_unet/Test_1\"\n",
    "os.makedirs(mdir, exist_ok=True)\n",
    "os.makedirs(rdir, exist_ok=True)\n",
    "\n",
    "# Define the tensorboard writer\n",
    "writer = SummaryWriter(\"./Runs_unet/Test_1\") # was runs_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/mpyrina/Notebooks/ANEMOI/ClimateDiffuse/src/')\n",
    "from DatasetCH import *\n",
    "from TrainDiffusion import *\n",
    "from TrainUnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unet only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - new upscale\n",
      "Loaded coarse data shape: (460, 11, 16, 32)\n",
      "Loaded high-resolution data shape: (460, 128, 256)\n",
      "Final coarse shape: torch.Size([5060, 1, 16, 32])\n",
      "Final fine shape: torch.Size([5060, 1, 128, 256])\n",
      "Input shape (should be [N, 1, H, W]): torch.Size([5060, 1, 128, 256])\n",
      "Dataset ready.\n",
      "Test - new upscale\n",
      "Loaded coarse data shape: (138, 11, 16, 32)\n",
      "Loaded high-resolution data shape: (138, 128, 256)\n",
      "Final coarse shape: torch.Size([1518, 1, 16, 32])\n",
      "Final fine shape: torch.Size([1518, 1, 128, 256])\n",
      "Input shape (should be [N, 1, H, W]): torch.Size([1518, 1, 128, 256])\n",
      "Dataset ready.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (map_layer0): Linear()\n",
       "  (map_layer1): Linear()\n",
       "  (enc): ModuleDict(\n",
       "    (256x128_conv): Conv2d()\n",
       "    (256x128_block0): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "    )\n",
       "    (256x128_block1): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "    )\n",
       "    (128x64_down): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (128x64_block0): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (128x64_block1): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "    )\n",
       "    (64x32_down): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (64x32_block0): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (64x32_block1): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "    )\n",
       "    (32x16_down): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (32x16_block0): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "      (norm2): GroupNorm()\n",
       "      (qkv): Conv2d()\n",
       "      (proj): Conv2d()\n",
       "    )\n",
       "    (32x16_block1): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (norm2): GroupNorm()\n",
       "      (qkv): Conv2d()\n",
       "      (proj): Conv2d()\n",
       "    )\n",
       "  )\n",
       "  (dec): ModuleDict(\n",
       "    (32x16_in0): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (norm2): GroupNorm()\n",
       "      (qkv): Conv2d()\n",
       "      (proj): Conv2d()\n",
       "    )\n",
       "    (32x16_in1): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "    )\n",
       "    (32x16_block0): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "      (norm2): GroupNorm()\n",
       "      (qkv): Conv2d()\n",
       "      (proj): Conv2d()\n",
       "    )\n",
       "    (32x16_block1): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "      (norm2): GroupNorm()\n",
       "      (qkv): Conv2d()\n",
       "      (proj): Conv2d()\n",
       "    )\n",
       "    (32x16_block2): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "      (norm2): GroupNorm()\n",
       "      (qkv): Conv2d()\n",
       "      (proj): Conv2d()\n",
       "    )\n",
       "    (64x32_up): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (64x32_block0): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (64x32_block1): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (64x32_block2): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (128x64_up): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (128x64_block0): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (128x64_block1): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (128x64_block2): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (256x128_up): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (256x128_block0): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (256x128_block1): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "    (256x128_block2): UNetBlock(\n",
       "      (norm0): GroupNorm()\n",
       "      (conv0): Conv2d()\n",
       "      (affine): Linear()\n",
       "      (norm1): GroupNorm()\n",
       "      (conv1): Conv2d()\n",
       "      (skip): Conv2d()\n",
       "    )\n",
       "  )\n",
       "  (out_norm): GroupNorm()\n",
       "  (out_conv): Conv2d()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the datasets\n",
    "ifs_dir = '/s2s/mpyrina/ECMWF_MCH/Europe_eval/s2s_hind_2022/all/'\n",
    "obs_dir = '/net/cfc/s2s_nobackup/mpyrina/TABSD_ifs_like/'\n",
    "\n",
    "# Run training for small number of epochs \n",
    "num_epochs = 10\n",
    "## Select hyperparameters of training\n",
    "batch_size = 16\n",
    "learning_rate = 1e-5 # try also 1e-5\n",
    "accum = 4\n",
    "\n",
    "dataset_train = UpscaleDataset(coarse_data_dir = ifs_dir, highres_data_dir = obs_dir,\n",
    "year_start=2002, year_end=2012, month=815,  \n",
    "constant_variables=None, constant_variables_filename=None)\n",
    "\n",
    "dataset_test = UpscaleDataset(coarse_data_dir = ifs_dir, highres_data_dir = obs_dir,\n",
    "year_start=2012, year_end=2015, month=815,  \n",
    "constant_variables=None, constant_variables_filename=None)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Define device\n",
    "device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# define the ml model : 1, 1, : 1 input var, one output\n",
    "unet_model = UNet((256, 128), 1, 1, label_dim=0, use_diffuse=False)\n",
    "unet_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47011/4068868327.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/home/mpyrina/.conda/envs/myenv_iacpy3_2023/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Train :: Epoch: 0:   0%|          | 1/317 [00:00<04:24,  1.19it/s]/home/mpyrina/Notebooks/ANEMOI/ClimateDiffuse/src_nan/TrainUnet.py:45: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/mpyrina/.conda/envs/myenv_iacpy3_2023/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   1%|          | 2/317 [02:06<6:29:42, 74.23s/it, Loss: 74.4895]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   1%|          | 3/317 [04:09<8:24:32, 96.41s/it, Loss: 73.1859]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   1%|▏         | 4/317 [06:19<9:31:56, 109.64s/it, Loss: 71.9187]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   2%|▏         | 5/317 [08:26<10:03:24, 116.04s/it, Loss: 73.9730]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   2%|▏         | 6/317 [10:31<10:16:27, 118.93s/it, Loss: 75.6871]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   2%|▏         | 7/317 [13:07<11:18:04, 131.24s/it, Loss: 73.2941]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   3%|▎         | 8/317 [15:55<12:15:10, 142.75s/it, Loss: 73.6491]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   3%|▎         | 9/317 [18:33<12:37:32, 147.57s/it, Loss: 65.2653]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   3%|▎         | 10/317 [20:59<12:33:46, 147.32s/it, Loss: 71.6232]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   3%|▎         | 11/317 [23:32<12:39:22, 148.90s/it, Loss: 70.0219]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   4%|▍         | 12/317 [26:07<12:47:00, 150.89s/it, Loss: 69.1445]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   4%|▍         | 13/317 [28:43<12:51:01, 152.18s/it, Loss: 82.8967]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   4%|▍         | 14/317 [31:05<12:33:30, 149.21s/it, Loss: 59.6708]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   5%|▍         | 15/317 [33:34<12:30:07, 149.03s/it, Loss: 72.0348]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   5%|▌         | 16/317 [35:51<12:10:55, 145.70s/it, Loss: 65.5133]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   5%|▌         | 17/317 [38:27<12:23:59, 148.80s/it, Loss: 81.1058]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   6%|▌         | 18/317 [40:46<12:05:26, 145.58s/it, Loss: 70.2962]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   6%|▌         | 19/317 [43:14<12:06:59, 146.37s/it, Loss: 65.4575]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   6%|▋         | 20/317 [45:39<12:02:39, 145.99s/it, Loss: 77.2573]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   7%|▋         | 21/317 [48:14<12:13:41, 148.72s/it, Loss: 70.0448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   7%|▋         | 22/317 [50:54<12:27:17, 151.99s/it, Loss: 73.7167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   7%|▋         | 23/317 [53:25<12:23:31, 151.74s/it, Loss: 67.7383]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   8%|▊         | 24/317 [56:07<12:36:10, 154.85s/it, Loss: 66.6025]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   8%|▊         | 25/317 [58:34<12:21:46, 152.42s/it, Loss: 73.1211]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   8%|▊         | 26/317 [1:01:00<12:09:49, 150.48s/it, Loss: 72.1336]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   9%|▊         | 27/317 [1:03:29<12:05:11, 150.04s/it, Loss: 62.1909]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   9%|▉         | 28/317 [1:05:49<11:49:28, 147.30s/it, Loss: 53.2730]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   9%|▉         | 29/317 [1:08:22<11:54:07, 148.77s/it, Loss: 71.9886]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:   9%|▉         | 30/317 [1:10:43<11:41:06, 146.57s/it, Loss: 70.5874]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  10%|▉         | 31/317 [1:13:05<11:31:46, 145.13s/it, Loss: 68.2840]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  10%|█         | 32/317 [1:15:17<11:11:02, 141.27s/it, Loss: 63.3348]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  10%|█         | 33/317 [1:17:39<11:09:01, 141.34s/it, Loss: 66.2377]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  11%|█         | 34/317 [1:19:50<10:52:06, 138.26s/it, Loss: 70.2363]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  11%|█         | 35/317 [1:22:01<10:40:35, 136.30s/it, Loss: 64.3474]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  11%|█▏        | 36/317 [1:24:12<10:30:02, 134.53s/it, Loss: 62.5688]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  12%|█▏        | 37/317 [1:26:38<10:44:06, 138.02s/it, Loss: 66.2871]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  12%|█▏        | 38/317 [1:28:50<10:33:00, 136.13s/it, Loss: 68.0551]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  12%|█▏        | 39/317 [1:30:58<10:20:17, 133.88s/it, Loss: 69.2942]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  13%|█▎        | 40/317 [1:33:14<10:20:37, 134.43s/it, Loss: 79.3365]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  13%|█▎        | 41/317 [1:35:33<10:24:40, 135.80s/it, Loss: 61.7838]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  13%|█▎        | 42/317 [1:37:49<10:22:30, 135.82s/it, Loss: 64.1727]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  14%|█▎        | 43/317 [1:40:07<10:22:43, 136.36s/it, Loss: 67.0859]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  14%|█▍        | 44/317 [1:42:23<10:20:42, 136.42s/it, Loss: 65.5102]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  14%|█▍        | 45/317 [1:44:46<10:26:44, 138.25s/it, Loss: 79.0348]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  15%|█▍        | 46/317 [1:46:49<10:04:46, 133.90s/it, Loss: 64.3207]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  15%|█▍        | 47/317 [1:49:01<9:59:44, 133.27s/it, Loss: 72.1984] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  15%|█▌        | 48/317 [1:51:11<9:53:18, 132.34s/it, Loss: 77.1421]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  15%|█▌        | 49/317 [1:53:34<10:04:25, 135.32s/it, Loss: 73.2192]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  16%|█▌        | 50/317 [1:55:57<10:12:19, 137.60s/it, Loss: 68.2882]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  16%|█▌        | 51/317 [1:58:37<10:40:10, 144.40s/it, Loss: 63.7964]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  16%|█▋        | 52/317 [2:01:11<10:50:48, 147.35s/it, Loss: 55.9922]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  17%|█▋        | 53/317 [2:03:52<11:06:10, 151.40s/it, Loss: 55.0010]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  17%|█▋        | 54/317 [2:06:21<11:00:15, 150.63s/it, Loss: 62.4493]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  17%|█▋        | 55/317 [2:08:53<10:59:15, 150.98s/it, Loss: 57.9033]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  18%|█▊        | 56/317 [2:11:30<11:05:08, 152.91s/it, Loss: 81.3299]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  18%|█▊        | 57/317 [2:14:13<11:16:22, 156.09s/it, Loss: 70.9298]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  18%|█▊        | 58/317 [2:16:43<11:05:12, 154.10s/it, Loss: 82.6049]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  19%|█▊        | 59/317 [2:19:18<11:03:30, 154.30s/it, Loss: 74.1823]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  19%|█▉        | 60/317 [2:21:53<11:02:39, 154.71s/it, Loss: 69.0910]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  19%|█▉        | 61/317 [2:24:33<11:06:45, 156.27s/it, Loss: 68.0549]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  20%|█▉        | 62/317 [2:26:59<10:50:53, 153.15s/it, Loss: 78.6462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  20%|█▉        | 63/317 [2:29:27<10:41:53, 151.63s/it, Loss: 63.4843]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  20%|██        | 64/317 [2:32:03<10:44:10, 152.77s/it, Loss: 77.2682]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  21%|██        | 65/317 [2:34:37<10:43:48, 153.29s/it, Loss: 65.9810]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  21%|██        | 66/317 [2:37:06<10:35:55, 152.01s/it, Loss: 68.9213]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  21%|██        | 67/317 [2:39:41<10:37:00, 152.88s/it, Loss: 63.8984]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  21%|██▏       | 68/317 [2:42:16<10:36:27, 153.36s/it, Loss: 69.4155]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  22%|██▏       | 69/317 [2:44:50<10:35:47, 153.82s/it, Loss: 67.9998]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  22%|██▏       | 70/317 [2:47:24<10:32:42, 153.69s/it, Loss: 60.0699]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  22%|██▏       | 71/317 [2:49:56<10:28:17, 153.24s/it, Loss: 77.1554]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  23%|██▎       | 72/317 [2:52:30<10:26:49, 153.51s/it, Loss: 73.5110]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  23%|██▎       | 73/317 [2:55:19<10:42:44, 158.05s/it, Loss: 70.4636]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  23%|██▎       | 74/317 [2:57:46<10:27:22, 154.91s/it, Loss: 65.5845]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  24%|██▎       | 75/317 [3:00:15<10:16:55, 152.96s/it, Loss: 75.4482]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  24%|██▍       | 76/317 [3:02:49<10:15:59, 153.36s/it, Loss: 91.5948]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  24%|██▍       | 77/317 [3:05:29<10:21:28, 155.37s/it, Loss: 67.4360]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  25%|██▍       | 78/317 [3:07:55<10:08:02, 152.65s/it, Loss: 88.6885]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  25%|██▍       | 79/317 [3:10:27<10:03:53, 152.24s/it, Loss: 64.4514]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  25%|██▌       | 80/317 [3:12:40<9:38:56, 146.57s/it, Loss: 62.8717] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  26%|██▌       | 81/317 [3:14:34<8:58:15, 136.84s/it, Loss: 73.4881]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  26%|██▌       | 82/317 [3:16:20<8:18:53, 127.38s/it, Loss: 62.6614]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  26%|██▌       | 83/317 [3:18:17<8:05:43, 124.54s/it, Loss: 70.7010]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  26%|██▋       | 84/317 [3:20:15<7:55:41, 122.49s/it, Loss: 58.3724]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  27%|██▋       | 85/317 [3:22:11<7:46:18, 120.60s/it, Loss: 80.2882]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  27%|██▋       | 86/317 [3:23:58<7:28:26, 116.48s/it, Loss: 82.2350]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  27%|██▋       | 87/317 [3:25:50<7:21:10, 115.09s/it, Loss: 89.2403]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  28%|██▊       | 88/317 [3:27:42<7:15:32, 114.12s/it, Loss: 60.5286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  28%|██▊       | 89/317 [3:29:34<7:11:15, 113.49s/it, Loss: 75.7076]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  28%|██▊       | 90/317 [3:31:18<6:58:13, 110.54s/it, Loss: 69.5946]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  29%|██▊       | 91/317 [3:33:09<6:56:58, 110.70s/it, Loss: 75.4118]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  29%|██▉       | 92/317 [3:35:04<7:00:13, 112.06s/it, Loss: 59.4630]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  29%|██▉       | 93/317 [3:36:57<6:59:49, 112.45s/it, Loss: 74.1810]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  30%|██▉       | 94/317 [3:38:40<6:46:34, 109.39s/it, Loss: 78.4948]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  30%|██▉       | 95/317 [3:40:31<6:46:49, 109.95s/it, Loss: 74.8985]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  30%|███       | 96/317 [3:42:34<6:59:20, 113.85s/it, Loss: 73.5611]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  31%|███       | 97/317 [3:44:29<6:59:16, 114.35s/it, Loss: 53.2880]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  31%|███       | 98/317 [3:46:07<6:39:03, 109.33s/it, Loss: 69.6886]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  31%|███       | 99/317 [3:47:55<6:35:45, 108.92s/it, Loss: 67.1115]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  32%|███▏      | 100/317 [3:49:52<6:43:09, 111.47s/it, Loss: 59.6809]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  32%|███▏      | 101/317 [3:51:53<6:51:29, 114.31s/it, Loss: 66.3889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  32%|███▏      | 102/317 [3:53:36<6:37:35, 110.95s/it, Loss: 78.9672]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  32%|███▏      | 103/317 [3:55:23<6:31:28, 109.76s/it, Loss: 54.8706]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  33%|███▎      | 104/317 [3:57:20<6:37:17, 111.91s/it, Loss: 69.8948]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  33%|███▎      | 105/317 [3:59:23<6:46:32, 115.06s/it, Loss: 62.0657]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  33%|███▎      | 106/317 [4:01:09<6:35:07, 112.36s/it, Loss: 66.2720]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  34%|███▍      | 107/317 [4:03:04<6:36:17, 113.23s/it, Loss: 61.0510]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  34%|███▍      | 108/317 [4:05:05<6:42:05, 115.43s/it, Loss: 66.4561]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  34%|███▍      | 109/317 [4:07:07<6:47:15, 117.48s/it, Loss: 58.3450]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  35%|███▍      | 110/317 [4:08:50<6:30:22, 113.15s/it, Loss: 71.3642]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  35%|███▌      | 111/317 [4:10:42<6:27:14, 112.79s/it, Loss: 61.5342]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  35%|███▌      | 112/317 [4:12:38<6:28:59, 113.85s/it, Loss: 73.8691]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  36%|███▌      | 113/317 [4:14:36<6:31:04, 115.02s/it, Loss: 82.4750]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  36%|███▌      | 114/317 [4:16:21<6:18:58, 112.01s/it, Loss: 57.8727]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  36%|███▋      | 115/317 [4:18:17<6:21:20, 113.27s/it, Loss: 60.3767]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  37%|███▋      | 116/317 [4:20:10<6:18:50, 113.09s/it, Loss: 71.0621]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  37%|███▋      | 117/317 [4:22:08<6:21:51, 114.56s/it, Loss: 66.2405]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  37%|███▋      | 118/317 [4:23:53<6:10:22, 111.67s/it, Loss: 77.6750]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  38%|███▊      | 119/317 [4:25:41<6:05:25, 110.73s/it, Loss: 60.0668]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  38%|███▊      | 120/317 [4:27:39<6:10:55, 112.97s/it, Loss: 70.3949]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  38%|███▊      | 121/317 [4:29:32<6:09:10, 113.01s/it, Loss: 70.7424]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  38%|███▊      | 122/317 [4:31:11<5:53:28, 108.76s/it, Loss: 58.6437]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  39%|███▉      | 123/317 [4:33:03<5:54:03, 109.50s/it, Loss: 59.1634]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  39%|███▉      | 124/317 [4:34:59<5:59:15, 111.69s/it, Loss: 82.7001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  39%|███▉      | 125/317 [4:36:58<6:03:48, 113.69s/it, Loss: 73.6202]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  40%|███▉      | 126/317 [4:38:46<5:57:04, 112.17s/it, Loss: 76.4687]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  40%|████      | 127/317 [4:40:35<5:52:18, 111.25s/it, Loss: 62.6314]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  40%|████      | 128/317 [4:42:32<5:55:22, 112.82s/it, Loss: 60.6606]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  41%|████      | 129/317 [4:44:33<6:01:30, 115.37s/it, Loss: 65.6684]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  41%|████      | 130/317 [4:46:22<5:53:02, 113.27s/it, Loss: 78.1613]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  41%|████▏     | 131/317 [4:48:14<5:50:14, 112.98s/it, Loss: 57.5185]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  42%|████▏     | 132/317 [4:49:35<5:18:32, 103.31s/it, Loss: 62.0660]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  42%|████▏     | 133/317 [4:50:58<4:58:37, 97.38s/it, Loss: 65.1307] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  42%|████▏     | 134/317 [4:52:20<4:42:43, 92.70s/it, Loss: 55.4257]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  43%|████▎     | 135/317 [4:53:53<4:41:25, 92.78s/it, Loss: 66.4366]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  43%|████▎     | 136/317 [4:55:32<4:45:33, 94.66s/it, Loss: 54.1257]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  43%|████▎     | 137/317 [4:57:31<5:06:16, 102.09s/it, Loss: 62.2488]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  44%|████▎     | 138/317 [4:59:37<5:25:26, 109.08s/it, Loss: 58.6299]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  44%|████▍     | 139/317 [5:01:43<5:38:42, 114.17s/it, Loss: 54.2823]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  44%|████▍     | 140/317 [5:04:03<5:59:24, 121.83s/it, Loss: 68.7124]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  44%|████▍     | 141/317 [5:06:28<6:17:58, 128.85s/it, Loss: 67.7926]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  45%|████▍     | 142/317 [5:08:37<6:15:49, 128.85s/it, Loss: 60.9456]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  45%|████▌     | 143/317 [5:10:49<6:16:32, 129.84s/it, Loss: 73.6598]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  45%|████▌     | 144/317 [5:13:06<6:20:29, 131.96s/it, Loss: 69.1464]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  46%|████▌     | 145/317 [5:15:34<6:32:42, 136.99s/it, Loss: 58.9024]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  46%|████▌     | 146/317 [5:18:29<7:02:44, 148.33s/it, Loss: 51.7536]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  46%|████▋     | 147/317 [5:20:45<6:49:50, 144.65s/it, Loss: 55.9082]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  47%|████▋     | 148/317 [5:23:05<6:42:54, 143.04s/it, Loss: 64.2273]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  47%|████▋     | 149/317 [5:25:27<6:39:57, 142.84s/it, Loss: 69.8670]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  47%|████▋     | 150/317 [5:27:42<6:30:57, 140.46s/it, Loss: 75.7930]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  48%|████▊     | 151/317 [5:29:56<6:23:00, 138.44s/it, Loss: 64.4640]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  48%|████▊     | 152/317 [5:32:10<6:17:34, 137.30s/it, Loss: 67.9189]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  48%|████▊     | 153/317 [5:34:28<6:15:48, 137.49s/it, Loss: 51.2004]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  49%|████▊     | 154/317 [5:36:45<6:12:53, 137.26s/it, Loss: 67.9356]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  49%|████▉     | 155/317 [5:39:00<6:08:46, 136.58s/it, Loss: 54.6073]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  49%|████▉     | 156/317 [5:41:15<6:04:57, 136.01s/it, Loss: 68.7391]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  50%|████▉     | 157/317 [5:43:39<6:09:43, 138.65s/it, Loss: 67.8274]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  50%|████▉     | 158/317 [5:45:58<6:07:41, 138.75s/it, Loss: 68.7240]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  50%|█████     | 159/317 [5:48:16<6:04:25, 138.39s/it, Loss: 74.3676]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  50%|█████     | 160/317 [5:50:30<5:58:53, 137.16s/it, Loss: 68.9912]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  51%|█████     | 161/317 [5:53:00<6:06:33, 140.99s/it, Loss: 72.0973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  51%|█████     | 162/317 [5:55:14<5:58:26, 138.75s/it, Loss: 58.7393]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  51%|█████▏    | 163/317 [5:57:36<5:59:13, 139.96s/it, Loss: 81.1973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  52%|█████▏    | 164/317 [5:59:49<5:51:23, 137.80s/it, Loss: 55.3260]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  52%|█████▏    | 165/317 [6:02:14<5:54:33, 139.96s/it, Loss: 78.6296]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  52%|█████▏    | 166/317 [6:04:26<5:46:11, 137.56s/it, Loss: 55.2160]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  53%|█████▎    | 167/317 [6:06:37<5:38:56, 135.57s/it, Loss: 60.3356]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  53%|█████▎    | 168/317 [6:08:59<5:41:13, 137.40s/it, Loss: 61.8467]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  53%|█████▎    | 169/317 [6:11:30<5:49:01, 141.50s/it, Loss: 72.0239]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  54%|█████▎    | 170/317 [6:13:45<5:42:06, 139.63s/it, Loss: 53.2507]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  54%|█████▍    | 171/317 [6:16:04<5:39:31, 139.53s/it, Loss: 63.6026]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  54%|█████▍    | 172/317 [6:18:22<5:35:50, 138.97s/it, Loss: 71.6785]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  55%|█████▍    | 173/317 [6:20:38<5:31:06, 137.96s/it, Loss: 64.6098]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  55%|█████▍    | 174/317 [6:22:45<5:21:31, 134.91s/it, Loss: 68.6864]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  55%|█████▌    | 175/317 [6:25:01<5:19:50, 135.14s/it, Loss: 83.5844]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  56%|█████▌    | 176/317 [6:27:14<5:16:07, 134.52s/it, Loss: 61.3373]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  56%|█████▌    | 177/317 [6:29:39<5:21:23, 137.74s/it, Loss: 67.3290]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  56%|█████▌    | 178/317 [6:31:55<5:17:31, 137.06s/it, Loss: 66.2862]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  56%|█████▋    | 179/317 [6:34:15<5:17:09, 137.90s/it, Loss: 58.7615]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  57%|█████▋    | 180/317 [6:36:42<5:21:09, 140.66s/it, Loss: 74.3205]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  57%|█████▋    | 181/317 [6:39:22<5:32:09, 146.54s/it, Loss: 55.6681]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  57%|█████▋    | 182/317 [6:41:41<5:24:24, 144.19s/it, Loss: 71.2990]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  58%|█████▊    | 183/317 [6:44:06<5:22:39, 144.48s/it, Loss: 62.1168]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  58%|█████▊    | 184/317 [6:46:25<5:16:47, 142.91s/it, Loss: 54.5249]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  58%|█████▊    | 185/317 [6:48:51<5:16:09, 143.71s/it, Loss: 65.8041]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  59%|█████▊    | 186/317 [6:51:09<5:09:55, 141.95s/it, Loss: 76.5608]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  59%|█████▉    | 187/317 [6:53:28<5:05:54, 141.19s/it, Loss: 68.1574]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  59%|█████▉    | 188/317 [6:55:41<4:58:15, 138.72s/it, Loss: 51.0688]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  60%|█████▉    | 189/317 [6:58:09<5:01:55, 141.52s/it, Loss: 72.6223]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  60%|█████▉    | 190/317 [7:00:28<4:58:03, 140.81s/it, Loss: 64.3292]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  60%|██████    | 191/317 [7:02:50<4:56:26, 141.16s/it, Loss: 81.0309]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  61%|██████    | 192/317 [7:05:10<4:53:16, 140.78s/it, Loss: 60.3440]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  61%|██████    | 193/317 [7:07:37<4:54:45, 142.62s/it, Loss: 59.6402]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  61%|██████    | 194/317 [7:09:46<4:43:40, 138.38s/it, Loss: 63.4500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  62%|██████▏   | 195/317 [7:12:03<4:41:04, 138.24s/it, Loss: 79.2557]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  62%|██████▏   | 196/317 [7:14:18<4:36:19, 137.02s/it, Loss: 61.2168]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  62%|██████▏   | 197/317 [7:16:44<4:39:24, 139.70s/it, Loss: 62.5236]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  62%|██████▏   | 198/317 [7:19:02<4:36:24, 139.36s/it, Loss: 59.0060]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  63%|██████▎   | 199/317 [7:21:24<4:35:30, 140.09s/it, Loss: 59.4508]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  63%|██████▎   | 200/317 [7:23:46<4:34:17, 140.66s/it, Loss: 68.9725]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  63%|██████▎   | 201/317 [7:26:11<4:34:37, 142.04s/it, Loss: 51.3521]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  64%|██████▎   | 202/317 [7:28:29<4:29:51, 140.80s/it, Loss: 66.2341]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  64%|██████▍   | 203/317 [7:30:50<4:27:22, 140.72s/it, Loss: 66.1941]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  64%|██████▍   | 204/317 [7:33:09<4:24:04, 140.21s/it, Loss: 55.7816]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  65%|██████▍   | 205/317 [7:35:32<4:23:15, 141.03s/it, Loss: 67.2880]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  65%|██████▍   | 206/317 [7:37:47<4:17:38, 139.26s/it, Loss: 71.8173]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  65%|██████▌   | 207/317 [7:40:09<4:16:43, 140.03s/it, Loss: 49.8692]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  66%|██████▌   | 208/317 [7:42:28<4:13:52, 139.75s/it, Loss: 64.3165]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  66%|██████▌   | 209/317 [7:44:59<4:17:38, 143.13s/it, Loss: 58.9202]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  66%|██████▌   | 210/317 [7:47:13<4:10:24, 140.42s/it, Loss: 63.8349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  67%|██████▋   | 211/317 [7:49:33<4:07:46, 140.25s/it, Loss: 56.8909]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  67%|██████▋   | 212/317 [7:51:56<4:07:16, 141.30s/it, Loss: 68.2299]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  67%|██████▋   | 213/317 [7:54:26<4:09:10, 143.75s/it, Loss: 61.8420]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  68%|██████▊   | 214/317 [7:56:44<4:04:01, 142.15s/it, Loss: 69.7144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  68%|██████▊   | 215/317 [7:59:07<4:02:10, 142.46s/it, Loss: 71.6204]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  68%|██████▊   | 216/317 [8:01:29<3:59:22, 142.20s/it, Loss: 65.6099]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  68%|██████▊   | 217/317 [8:04:04<4:03:22, 146.02s/it, Loss: 69.7027]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  69%|██████▉   | 218/317 [8:06:22<3:57:01, 143.65s/it, Loss: 77.6513]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  69%|██████▉   | 219/317 [8:08:49<3:56:13, 144.62s/it, Loss: 74.7057]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  69%|██████▉   | 220/317 [8:11:09<3:51:45, 143.35s/it, Loss: 54.9480]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  70%|██████▉   | 221/317 [8:13:44<3:54:48, 146.75s/it, Loss: 71.6994]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  70%|███████   | 222/317 [8:16:01<3:47:40, 143.79s/it, Loss: 47.7248]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  70%|███████   | 223/317 [8:18:22<3:44:04, 143.02s/it, Loss: 57.0801]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  71%|███████   | 224/317 [8:20:45<3:41:27, 142.88s/it, Loss: 64.0247]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  71%|███████   | 225/317 [8:23:13<3:41:30, 144.46s/it, Loss: 73.5559]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  71%|███████▏  | 226/317 [8:25:26<3:34:08, 141.20s/it, Loss: 73.8511]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  72%|███████▏  | 227/317 [8:27:51<3:33:17, 142.19s/it, Loss: 63.5632]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  72%|███████▏  | 228/317 [8:30:15<3:31:39, 142.69s/it, Loss: 69.2519]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  72%|███████▏  | 229/317 [8:32:47<3:33:28, 145.55s/it, Loss: 59.9852]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  73%|███████▎  | 230/317 [8:35:02<3:26:19, 142.29s/it, Loss: 63.1278]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  73%|███████▎  | 231/317 [8:37:24<3:23:54, 142.26s/it, Loss: 59.7684]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  73%|███████▎  | 232/317 [8:39:39<3:18:36, 140.20s/it, Loss: 61.7630]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  74%|███████▎  | 233/317 [8:42:08<3:19:55, 142.81s/it, Loss: 64.7970]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  74%|███████▍  | 234/317 [8:44:23<3:14:04, 140.30s/it, Loss: 60.3049]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  74%|███████▍  | 235/317 [8:46:51<3:15:01, 142.70s/it, Loss: 50.3646]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  74%|███████▍  | 236/317 [8:49:12<3:11:51, 142.12s/it, Loss: 55.7193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  75%|███████▍  | 237/317 [8:51:47<3:14:37, 145.97s/it, Loss: 72.0331]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  75%|███████▌  | 238/317 [8:54:07<3:09:54, 144.23s/it, Loss: 74.3197]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  75%|███████▌  | 239/317 [8:56:29<3:06:53, 143.76s/it, Loss: 58.1208]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  76%|███████▌  | 240/317 [8:58:54<3:04:44, 143.95s/it, Loss: 66.8415]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  76%|███████▌  | 241/317 [9:01:31<3:07:22, 147.93s/it, Loss: 61.9953]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  76%|███████▋  | 242/317 [9:03:48<3:00:44, 144.59s/it, Loss: 67.4487]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  77%|███████▋  | 243/317 [9:06:07<2:56:08, 142.81s/it, Loss: 58.4065]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  77%|███████▋  | 244/317 [9:08:32<2:54:40, 143.56s/it, Loss: 74.7271]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  77%|███████▋  | 245/317 [9:11:01<2:54:17, 145.24s/it, Loss: 50.0940]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  78%|███████▊  | 246/317 [9:13:14<2:47:31, 141.57s/it, Loss: 58.4292]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  78%|███████▊  | 247/317 [9:15:37<2:45:33, 141.91s/it, Loss: 57.4569]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  78%|███████▊  | 248/317 [9:17:58<2:42:59, 141.73s/it, Loss: 80.2499]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  79%|███████▊  | 249/317 [9:20:34<2:45:22, 145.92s/it, Loss: 62.2634]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  79%|███████▉  | 250/317 [9:22:52<2:40:30, 143.74s/it, Loss: 67.7465]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  79%|███████▉  | 251/317 [9:25:18<2:38:35, 144.18s/it, Loss: 71.9307]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  79%|███████▉  | 252/317 [9:27:46<2:37:25, 145.32s/it, Loss: 70.0061]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  80%|███████▉  | 253/317 [9:30:13<2:35:32, 145.81s/it, Loss: 63.0316]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  80%|████████  | 254/317 [9:32:33<2:31:25, 144.22s/it, Loss: 60.6778]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  80%|████████  | 255/317 [9:34:54<2:27:56, 143.17s/it, Loss: 70.6645]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  81%|████████  | 256/317 [9:37:14<2:24:33, 142.19s/it, Loss: 69.4601]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  81%|████████  | 257/317 [9:39:40<2:23:26, 143.43s/it, Loss: 61.0438]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  81%|████████▏ | 258/317 [9:42:03<2:20:56, 143.33s/it, Loss: 61.8432]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  82%|████████▏ | 259/317 [9:44:26<2:18:28, 143.24s/it, Loss: 68.0107]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  82%|████████▏ | 260/317 [9:46:42<2:14:00, 141.07s/it, Loss: 63.1203]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  82%|████████▏ | 261/317 [9:49:21<2:16:38, 146.40s/it, Loss: 57.4933]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  83%|████████▎ | 262/317 [9:51:40<2:12:06, 144.11s/it, Loss: 62.1856]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  83%|████████▎ | 263/317 [9:54:04<2:09:49, 144.25s/it, Loss: 63.4471]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  83%|████████▎ | 264/317 [9:56:28<2:07:09, 143.95s/it, Loss: 53.5528]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  84%|████████▎ | 265/317 [9:59:02<2:07:35, 147.22s/it, Loss: 66.1393]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  84%|████████▍ | 266/317 [10:01:18<2:02:09, 143.72s/it, Loss: 63.1910]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  84%|████████▍ | 267/317 [10:03:46<2:00:48, 144.96s/it, Loss: 62.6945]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  85%|████████▍ | 268/317 [10:06:10<1:58:10, 144.70s/it, Loss: 69.1229]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  85%|████████▍ | 269/317 [10:08:44<1:57:55, 147.40s/it, Loss: 54.8940]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  85%|████████▌ | 270/317 [10:10:59<1:52:43, 143.91s/it, Loss: 60.2276]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  85%|████████▌ | 271/317 [10:13:30<1:51:58, 146.06s/it, Loss: 59.0955]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  86%|████████▌ | 272/317 [10:15:58<1:49:49, 146.42s/it, Loss: 50.9600]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  86%|████████▌ | 273/317 [10:18:29<1:48:25, 147.85s/it, Loss: 70.7034]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  86%|████████▋ | 274/317 [10:20:51<1:44:45, 146.17s/it, Loss: 67.3152]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  87%|████████▋ | 275/317 [10:23:18<1:42:30, 146.44s/it, Loss: 49.3167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  87%|████████▋ | 276/317 [10:25:38<1:38:41, 144.42s/it, Loss: 61.9493]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  87%|████████▋ | 277/317 [10:28:13<1:38:27, 147.70s/it, Loss: 74.3240]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  88%|████████▊ | 278/317 [10:30:43<1:36:22, 148.27s/it, Loss: 61.2203]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  88%|████████▊ | 279/317 [10:33:10<1:33:40, 147.92s/it, Loss: 78.4854]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  88%|████████▊ | 280/317 [10:35:31<1:29:55, 145.83s/it, Loss: 65.1910]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  89%|████████▊ | 281/317 [10:38:11<1:30:04, 150.13s/it, Loss: 60.2473]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  89%|████████▉ | 282/317 [10:40:37<1:26:48, 148.82s/it, Loss: 62.4473]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  89%|████████▉ | 283/317 [10:43:03<1:23:55, 148.09s/it, Loss: 50.7627]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  90%|████████▉ | 284/317 [10:45:31<1:21:26, 148.07s/it, Loss: 77.5541]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  90%|████████▉ | 285/317 [10:48:14<1:21:19, 152.48s/it, Loss: 50.5756]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  90%|█████████ | 286/317 [10:50:35<1:16:57, 148.94s/it, Loss: 62.9716]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  91%|█████████ | 287/317 [10:53:07<1:14:55, 149.85s/it, Loss: 55.1146]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  91%|█████████ | 288/317 [10:55:42<1:13:09, 151.36s/it, Loss: 74.6508]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  91%|█████████ | 289/317 [10:58:20<1:11:33, 153.35s/it, Loss: 62.6732]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  91%|█████████▏| 290/317 [11:00:34<1:06:26, 147.65s/it, Loss: 78.2833]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  92%|█████████▏| 291/317 [11:02:59<1:03:36, 146.79s/it, Loss: 60.2522]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  92%|█████████▏| 292/317 [11:05:15<59:47, 143.51s/it, Loss: 63.2414]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  92%|█████████▏| 293/317 [11:07:44<58:04, 145.17s/it, Loss: 59.3721]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  93%|█████████▎| 294/317 [11:10:02<54:54, 143.22s/it, Loss: 55.5195]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  93%|█████████▎| 295/317 [11:12:31<53:05, 144.81s/it, Loss: 74.8718]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  93%|█████████▎| 296/317 [11:14:54<50:33, 144.47s/it, Loss: 67.8086]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  94%|█████████▎| 297/317 [11:17:31<49:20, 148.01s/it, Loss: 67.4742]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  94%|█████████▍| 298/317 [11:19:54<46:27, 146.71s/it, Loss: 56.0705]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  94%|█████████▍| 299/317 [11:22:24<44:17, 147.65s/it, Loss: 64.0439]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  95%|█████████▍| 300/317 [11:24:50<41:41, 147.15s/it, Loss: 58.4753]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  95%|█████████▍| 301/317 [11:27:25<39:49, 149.36s/it, Loss: 65.1658]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  95%|█████████▌| 302/317 [11:29:51<37:05, 148.34s/it, Loss: 64.8135]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  96%|█████████▌| 303/317 [11:32:16<34:25, 147.55s/it, Loss: 58.0772]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  96%|█████████▌| 304/317 [11:34:49<32:18, 149.10s/it, Loss: 66.9011]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  96%|█████████▌| 305/317 [11:37:23<30:07, 150.64s/it, Loss: 56.2185]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  97%|█████████▋| 306/317 [11:39:48<27:17, 148.85s/it, Loss: 57.5972]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  97%|█████████▋| 307/317 [11:42:21<24:59, 149.97s/it, Loss: 61.6063]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  97%|█████████▋| 308/317 [11:44:51<22:29, 149.97s/it, Loss: 61.4079]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  97%|█████████▋| 309/317 [11:47:23<20:04, 150.58s/it, Loss: 71.9887]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  98%|█████████▊| 310/317 [11:49:37<16:59, 145.59s/it, Loss: 72.5853]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  98%|█████████▊| 311/317 [11:52:00<14:30, 145.02s/it, Loss: 54.6593]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  98%|█████████▊| 312/317 [11:54:29<12:10, 146.18s/it, Loss: 64.8342]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  99%|█████████▊| 313/317 [11:56:59<09:49, 147.41s/it, Loss: 64.5265]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  99%|█████████▉| 314/317 [11:59:25<07:20, 146.74s/it, Loss: 66.4329]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0:  99%|█████████▉| 315/317 [12:01:53<04:54, 147.30s/it, Loss: 72.2339]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0: 100%|█████████▉| 316/317 [12:04:18<02:26, 146.69s/it, Loss: 70.0285]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0: 100%|██████████| 317/317 [12:06:59<00:00, 150.79s/it, Loss: 74.3799]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([4, 1, 128, 256])\n",
      "Batch output shape: torch.Size([4, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([4, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([4, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([4, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([4, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([4, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([4, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([4, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([4, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([4, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([4, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([4, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([4, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([4, 1024, 16, 32])\n",
      "x.shape: torch.Size([4, 1024, 16, 32]), skips[-1].shape: torch.Size([4, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([4, 2048, 16, 32])\n",
      "x.shape: torch.Size([4, 1024, 16, 32]), skips[-1].shape: torch.Size([4, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([4, 2048, 16, 32])\n",
      "x.shape: torch.Size([4, 1024, 16, 32]), skips[-1].shape: torch.Size([4, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([4, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([4, 1024, 16, 32])\n",
      "x.shape: torch.Size([4, 1024, 32, 64]), skips[-1].shape: torch.Size([4, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([4, 1536, 32, 64])\n",
      "x.shape: torch.Size([4, 512, 32, 64]), skips[-1].shape: torch.Size([4, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([4, 1024, 32, 64])\n",
      "x.shape: torch.Size([4, 512, 32, 64]), skips[-1].shape: torch.Size([4, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([4, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([4, 512, 32, 64])\n",
      "x.shape: torch.Size([4, 512, 64, 128]), skips[-1].shape: torch.Size([4, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([4, 768, 64, 128])\n",
      "x.shape: torch.Size([4, 256, 64, 128]), skips[-1].shape: torch.Size([4, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([4, 512, 64, 128])\n",
      "x.shape: torch.Size([4, 256, 64, 128]), skips[-1].shape: torch.Size([4, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([4, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([4, 256, 64, 128])\n",
      "x.shape: torch.Size([4, 256, 128, 256]), skips[-1].shape: torch.Size([4, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([4, 384, 128, 256])\n",
      "x.shape: torch.Size([4, 128, 128, 256]), skips[-1].shape: torch.Size([4, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([4, 256, 128, 256])\n",
      "x.shape: torch.Size([4, 128, 128, 256]), skips[-1].shape: torch.Size([4, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([4, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 0: 100%|██████████| 317/317 [12:07:55<00:00, 137.78s/it, Loss: 66.2658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./Model_unet/Test_1/unet_model_epoch_0.pt\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "Predicted output shape: torch.Size([16, 1, 128, 256])\n",
      "Predicted output min: 271.89227294921875, max: 301.9680480957031\n",
      "Predicted output mean: 288.4302978515625, std: 4.2827043533325195\n",
      "Shape of `coarse` (from batch, eg 8, 1, 11, 18: torch.Size([16, 1, 128, 256])\n",
      "Shape of `fine ground truth` (from batch), eg 8, 1, 128, 256: torch.Size([16, 1, 128, 256])\n",
      "Shape of `images_input` (to model), is same as `coarse`: torch.Size([16, 1, 128, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   0%|          | 1/317 [00:01<08:26,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   1%|          | 2/317 [02:30<7:43:54, 88.36s/it, Loss: 70.4736]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   1%|          | 3/317 [04:57<10:01:38, 114.96s/it, Loss: 60.1174]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   1%|▏         | 4/317 [07:26<11:10:45, 128.58s/it, Loss: 65.1432]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   2%|▏         | 5/317 [09:57<11:50:10, 136.57s/it, Loss: 50.9234]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   2%|▏         | 6/317 [12:20<11:59:14, 138.76s/it, Loss: 64.2396]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   2%|▏         | 7/317 [14:47<12:10:25, 141.37s/it, Loss: 67.1216]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   3%|▎         | 8/317 [17:12<12:14:09, 142.56s/it, Loss: 56.5797]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   3%|▎         | 9/317 [19:40<12:20:34, 144.27s/it, Loss: 55.3091]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   3%|▎         | 10/317 [22:06<12:20:52, 144.79s/it, Loss: 66.2903]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   3%|▎         | 11/317 [24:35<12:25:03, 146.09s/it, Loss: 62.0692]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   4%|▍         | 12/317 [26:59<12:20:16, 145.63s/it, Loss: 65.9101]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   4%|▍         | 13/317 [29:25<12:18:25, 145.74s/it, Loss: 54.5959]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   4%|▍         | 14/317 [31:47<12:09:05, 144.37s/it, Loss: 58.8668]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   5%|▍         | 15/317 [34:11<12:06:22, 144.31s/it, Loss: 73.2944]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   5%|▌         | 16/317 [36:29<11:55:04, 142.54s/it, Loss: 71.2763]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   5%|▌         | 17/317 [39:03<12:09:45, 145.95s/it, Loss: 64.7946]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   6%|▌         | 18/317 [41:28<12:05:47, 145.64s/it, Loss: 65.3803]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   6%|▌         | 19/317 [43:54<12:03:34, 145.69s/it, Loss: 62.0042]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   6%|▋         | 20/317 [47:09<13:13:59, 160.40s/it, Loss: 63.2042]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   7%|▋         | 21/317 [49:41<13:00:05, 158.13s/it, Loss: 78.9551]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   7%|▋         | 22/317 [52:07<12:39:19, 154.44s/it, Loss: 58.7448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   7%|▋         | 23/317 [54:32<12:22:05, 151.45s/it, Loss: 77.7331]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   8%|▊         | 24/317 [56:57<12:10:19, 149.56s/it, Loss: 67.2867]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   8%|▊         | 25/317 [59:25<12:06:29, 149.28s/it, Loss: 57.9990]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   8%|▊         | 26/317 [1:01:41<11:44:34, 145.27s/it, Loss: 63.9552]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   9%|▊         | 27/317 [1:04:04<11:38:26, 144.51s/it, Loss: 59.2052]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   9%|▉         | 28/317 [1:06:28<11:34:36, 144.21s/it, Loss: 52.8053]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   9%|▉         | 29/317 [1:08:58<11:40:54, 146.02s/it, Loss: 64.1473]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:   9%|▉         | 30/317 [1:11:20<11:33:03, 144.89s/it, Loss: 79.7987]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  10%|▉         | 31/317 [1:13:52<11:40:02, 146.86s/it, Loss: 72.9693]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  10%|█         | 32/317 [1:16:18<11:36:16, 146.58s/it, Loss: 72.0674]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  10%|█         | 33/317 [1:18:44<11:33:23, 146.49s/it, Loss: 79.9168]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  11%|█         | 34/317 [1:21:11<11:31:49, 146.68s/it, Loss: 54.7876]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  11%|█         | 35/317 [1:23:36<11:27:38, 146.31s/it, Loss: 69.1254]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  11%|█▏        | 36/317 [1:25:56<11:15:30, 144.24s/it, Loss: 69.2770]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  12%|█▏        | 37/317 [1:28:20<11:13:45, 144.38s/it, Loss: 72.6373]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  12%|█▏        | 38/317 [1:30:46<11:12:58, 144.72s/it, Loss: 60.4818]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  12%|█▏        | 39/317 [1:33:09<11:07:58, 144.17s/it, Loss: 69.9915]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  13%|█▎        | 40/317 [1:35:26<10:55:56, 142.08s/it, Loss: 59.8411]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  13%|█▎        | 41/317 [1:38:03<11:14:10, 146.56s/it, Loss: 55.8124]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  13%|█▎        | 42/317 [1:40:31<11:13:18, 146.91s/it, Loss: 58.8651]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  14%|█▎        | 43/317 [1:42:50<11:00:51, 144.71s/it, Loss: 45.0120]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  14%|█▍        | 44/317 [1:45:18<11:02:25, 145.59s/it, Loss: 68.3339]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  14%|█▍        | 45/317 [1:47:51<11:10:38, 147.94s/it, Loss: 54.7686]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  15%|█▍        | 46/317 [1:50:15<11:02:03, 146.58s/it, Loss: 51.5266]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  15%|█▍        | 47/317 [1:52:39<10:56:23, 145.86s/it, Loss: 40.5788]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  15%|█▌        | 48/317 [1:55:04<10:52:36, 145.56s/it, Loss: 60.7577]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  15%|█▌        | 49/317 [1:57:35<10:57:05, 147.11s/it, Loss: 46.7591]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  16%|█▌        | 50/317 [1:59:56<10:47:30, 145.51s/it, Loss: 59.3875]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  16%|█▌        | 51/317 [2:02:23<10:46:16, 145.78s/it, Loss: 60.4935]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  16%|█▋        | 52/317 [2:04:46<10:40:52, 145.10s/it, Loss: 74.4601]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  17%|█▋        | 53/317 [2:07:14<10:41:15, 145.74s/it, Loss: 46.9248]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  17%|█▋        | 54/317 [2:09:41<10:41:36, 146.37s/it, Loss: 76.1550]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  17%|█▋        | 55/317 [2:12:11<10:42:49, 147.21s/it, Loss: 53.8340]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  18%|█▊        | 56/317 [2:14:32<10:32:42, 145.45s/it, Loss: 58.0720]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  18%|█▊        | 57/317 [2:17:03<10:37:30, 147.12s/it, Loss: 61.1746]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  18%|█▊        | 58/317 [2:19:28<10:32:33, 146.54s/it, Loss: 68.4434]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  19%|█▊        | 59/317 [2:21:52<10:26:24, 145.68s/it, Loss: 62.8212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  19%|█▉        | 60/317 [2:24:14<10:19:09, 144.55s/it, Loss: 58.0209]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  19%|█▉        | 61/317 [2:26:45<10:25:06, 146.51s/it, Loss: 56.0557]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  20%|█▉        | 62/317 [2:29:06<10:15:36, 144.85s/it, Loss: 65.7016]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([16, 1, 128, 256])\n",
      "Batch output shape: torch.Size([16, 1, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 1024, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 2048, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 16, 32]), skips[-1].shape: torch.Size([16, 512, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1536, 16, 32])\n",
      "Input shape to conv0: torch.Size([16, 1024, 16, 32])\n",
      "x.shape: torch.Size([16, 1024, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1536, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 512, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 1024, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 32, 64]), skips[-1].shape: torch.Size([16, 256, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 768, 32, 64])\n",
      "Input shape to conv0: torch.Size([16, 512, 32, 64])\n",
      "x.shape: torch.Size([16, 512, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 768, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 256, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 512, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 64, 128]), skips[-1].shape: torch.Size([16, 128, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 384, 64, 128])\n",
      "Input shape to conv0: torch.Size([16, 256, 64, 128])\n",
      "x.shape: torch.Size([16, 256, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 384, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n",
      "x.shape: torch.Size([16, 128, 128, 256]), skips[-1].shape: torch.Size([16, 128, 128, 256])\n",
      "Input shape to conv0: torch.Size([16, 256, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :: Epoch: 1:  20%|█▉        | 62/317 [2:31:17<10:22:15, 146.41s/it, Loss: 65.7016]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# best modes\u001b[39;00m\n\u001b[1;32m     17\u001b[0m mbest \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/best_unet_model_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43munet_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Save the model weights\u001b[39;00m\n",
      "File \u001b[0;32m~/Notebooks/ANEMOI/ClimateDiffuse/src_nan/TrainUnet.py:68\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, loss_fn, data_loader, optimiser, scaler, step, accum, writer, device)\u001b[0m\n\u001b[1;32m     63\u001b[0m     else:\n\u001b[1;32m     64\u001b[0m         # If no valid pixels in the current batch, return a zero loss\n\u001b[1;32m     65\u001b[0m         loss = torch.tensor(0.0, device=image_output.device, dtype=image_output.dtype)\n\u001b[1;32m     66\u001b[0m     # --- END MODIFICATION ---\n\u001b[1;32m     67\u001b[0m \n\u001b[0;32m---> 68\u001b[0m # backpropagation\n\u001b[1;32m     69\u001b[0m scaler.scale(loss).backward()\n\u001b[1;32m     70\u001b[0m step_loss += loss.item() # Accumulate loss for print/tensorboard\n",
      "File \u001b[0;32m~/.conda/envs/myenv_iacpy3_2023/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv_iacpy3_2023/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv_iacpy3_2023/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# define the optimiser\n",
    "optimiser = torch.optim.AdamW(unet_model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# train the model\n",
    "losses = []\n",
    "for step in range(num_epochs):\n",
    "    # model_save\n",
    "    model_save_path = f\"{mdir}/unet_model_epoch_{step}.pt\"\n",
    "    # fig_save\n",
    "    fig_save_path = f\"{rdir}/{step}.png\"\n",
    "    # best modes\n",
    "    mbest = f\"{mdir}/best_unet_model_epoch_{step}.pt\"\n",
    "\n",
    "    epoch_loss = train_step(\n",
    "        unet_model, loss_fn, dataloader_train, optimiser,\n",
    "        scaler, step, accum, writer, device=device)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    # Save the model weights\n",
    "    model_save_path = f\"{mdir}/unet_model_epoch_{step}.pt\"\n",
    "    torch.save(unet_model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    (fig, ax), (base_error, pred_error), predicted_numpy_array = sample_model(\n",
    "        unet_model, dataloader_test, device=device)\n",
    "    plt.show()\n",
    "    fig.savefig(fig_save_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "    writer.add_scalar(\"Error/base\", base_error, step)\n",
    "    writer.add_scalar(\"Error/pred\", pred_error, step)\n",
    "\n",
    "    # save the model\n",
    "    if losses[-1] == min(losses):\n",
    "        torch.save(unet_model.state_dict(), mbest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "avg_pred_error, avg_base_error = evaluate_model(unet_model, loss_fn, dataloader_test, device=device)\n",
    "\n",
    "print(f\"\\nFinal Evaluation on Test Set:\")\n",
    "print(f\"Average Prediction Error (MAE): {avg_pred_error:.4f}\")\n",
    "print(f\"Average Baseline Error (Coarse vs. Ground Truth MAE): {avg_base_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv_iacpy3_2023]",
   "language": "python",
   "name": "conda-env-.conda-myenv_iacpy3_2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
