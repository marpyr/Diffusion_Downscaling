{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "\n",
    "from DatasetCH import UpscaleDataset\n",
    "from models import *\n",
    "import Network\n",
    "\n",
    "# Make dirs\n",
    "mdir=\"./Model_unet/Test_1\"\n",
    "rdir=\"./Results_unet/Test_1\"\n",
    "os.makedirs(mdir, exist_ok=True)\n",
    "os.makedirs(rdir, exist_ok=True)\n",
    "\n",
    "# Define the tensorboard writer\n",
    "writer = SummaryWriter(\"./Runs_unet/Test_1\") # was runs_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/mpyrina/Notebooks/ANEMOI/ClimateDiffuse/src/')\n",
    "from DatasetCH import *\n",
    "from TrainDiffusion import *\n",
    "from TrainUnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unet only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the datasets\n",
    "ifs_dir = '/s2s/mpyrina/ECMWF_MCH/Europe_eval/s2s_hind_2022/all/'\n",
    "obs_dir = '/net/cfc/s2s_nobackup/mpyrina/TABSD_ifs_like/'\n",
    "\n",
    "# Run training for small number of epochs \n",
    "num_epochs = 12\n",
    "## Select hyperparameters of training\n",
    "batch_size = 8\n",
    "learning_rate = 1e-5 # try also 1e-5\n",
    "accum = 8\n",
    "\n",
    "dataset_train = UpscaleDataset(coarse_data_dir = ifs_dir, highres_data_dir = obs_dir,\n",
    "year_start=2002, year_end=2012, month=815,  \n",
    "constant_variables=None, constant_variables_filename=None)\n",
    "\n",
    "dataset_test = UpscaleDataset(coarse_data_dir = ifs_dir, highres_data_dir = obs_dir,\n",
    "year_start=2012, year_end=2015, month=815,  \n",
    "constant_variables=None, constant_variables_filename=None)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Define device\n",
    "device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# define the ml model : 1, 1, : 1 input var, one output\n",
    "unet_model = UNet((256, 128), 1, 1, label_dim=0, use_diffuse=False)\n",
    "unet_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# define the optimiser\n",
    "optimiser = torch.optim.AdamW(unet_model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# train the model\n",
    "losses = []\n",
    "for step in range(num_epochs):\n",
    "    # model_save\n",
    "    model_save_path = f\"{mdir}/unet_model_epoch_{step}.pt\"\n",
    "    # fig_save\n",
    "    fig_save_path = f\"{rdir}/{step}.png\"\n",
    "    # best modes\n",
    "    mbest = f\"{mdir}/best_unet_model_epoch_{step}.pt\"\n",
    "\n",
    "    epoch_loss = train_step(\n",
    "        unet_model, loss_fn, dataloader_train, optimiser,\n",
    "        scaler, step, accum, writer, device=device)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    # Save the model weights\n",
    "    model_save_path = f\"{mdir}/unet_model_epoch_{step}.pt\"\n",
    "    torch.save(unet_model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    (fig, ax), (base_error, pred_error), predicted_numpy_array = sample_model(\n",
    "        unet_model, dataloader_test, device=device)\n",
    "    plt.show()\n",
    "    fig.savefig(fig_save_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "    writer.add_scalar(\"Error/base\", base_error, step)\n",
    "    writer.add_scalar(\"Error/pred\", pred_error, step)\n",
    "\n",
    "    # save the model\n",
    "    if losses[-1] == min(losses):\n",
    "        torch.save(unet_model.state_dict(), mbest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "avg_pred_error, avg_base_error = evaluate_model(unet_model, loss_fn, dataloader_test, device=device)\n",
    "\n",
    "print(f\"\\nFinal Evaluation on Test Set:\")\n",
    "print(f\"Average Prediction Error (MAE): {avg_pred_error:.4f}\")\n",
    "print(f\"Average Baseline Error (Coarse vs. Ground Truth MAE): {avg_base_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv_iacpy3_2023]",
   "language": "python",
   "name": "conda-env-.conda-myenv_iacpy3_2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
